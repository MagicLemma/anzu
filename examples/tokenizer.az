
struct tokenizer
{
    _string: char const[];
    _delim: char;
    _start: u64;
    _curr: u64;

    fn advance(self: &) -> null
    {
        # we are at the last word, so "advance" just invalidates the tokenizer
        if self._curr == self._string.size() {
            self._start = self._curr;
            return;
        }

        # if we are not at the first word, we need to update the start location
        if self._curr > 0u {
            self._curr = self._curr + 1u;
            self._start = self._curr;
        }

        while self._curr < self._string.size() && self._string[self._curr] != self._delim {
            self._curr = self._curr + 1u;
        }
    }

    fn valid(self: const&) -> bool
    {
        return self._start != self._string.size();
    }

    fn current(self: const&) -> char const[]
    {
        return self._string[self._start : self._curr];
    }
}

fn new_tokenizer(input: char const[], delim: char) -> tokenizer
{
    var t := tokenizer(input, delim, 0u, 0u);
    t.advance(); # prime the tokenizer at the first word
    return t;
}

let input := "my test string has six words";

var tok := new_tokenizer(input, ' ');
while tok.valid() {
    print("{}\n", tok.current());
    tok.advance();
}